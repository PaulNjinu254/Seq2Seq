{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOX0BW3WeACdXRrYZjx6pbN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PaulNjinu254/Seq2Seq/blob/main/Seq2Seq.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "izMG7U0p49g3",
        "outputId": "670c4e46-1e90-445f-8ac4-229ecfe6a9d5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nLines 1 to 6: Model metadata ‚Äî title, author, date info, description, accelerator.\\n\\nLines 8 to 29: Introduction ‚Äî explains the model purpose, dataset, and training/inference workflow.\\n\\nLines 31 to 33: Section header ‚Äî Setup.\\n\\nLines 35 to 39: Import libraries ‚Äî numpy, keras, os, Path.\\n\\nLines 41 to 43: Section header ‚Äî Download the data.\\n\\nLines 45 to 47: Download and unzip English‚ÄìFrench dataset.\\n\\nLines 49 to 56: Section header ‚Äî Configuration.\\n\\nLines 58 to 63: Hyperparameters and dataset path.\\n\\nLines 65 to 67: Section header ‚Äî Prepare the data.\\n\\nLines 69 to 73: Initialize storage lists and sets for texts and characters.\\n\\nLines 74 to 76: Read dataset file.\\n\\nLines 77 to 85: Process lines, add start/end tokens, store texts, collect characters.\\n\\nLines 87 to 91: Sort characters, compute vocab sizes, and max sequence lengths.\\n\\nLines 93 to 97: Print dataset statistics.\\n\\nLines 99 to 100: Create character-to-index dictionaries.\\n\\nLines 102 to 110: Initialize NumPy arrays for encoder/decoder one-hot data.\\n\\nLines 112 to 121: Populate one-hot encoded arrays with sequences and padding.\\n\\nLines 123 to 125: Section header ‚Äî Build the model.\\n\\nLines 127 to 129: Define encoder input + LSTM + extract states.\\n\\nLines 131 to 132: Store encoder states.\\n\\nLines 134 to 135: Define decoder input.\\n\\nLines 137 to 141: Define decoder LSTM + dense softmax output layer.\\n\\nLines 143 to 145: Create training model.\\n\\nLines 147 to 149: Section header ‚Äî Train the model.\\n\\nLines 151 to 153: Compile model.\\n\\nLines 154 to 160: Train model, save to disk.\\n\\nLines 162 to 168: Section header ‚Äî Run inference (sampling).\\n\\nLines 171 to 175: Reload model from disk.\\n\\nLines 177 to 180: Build encoder inference model.\\n\\nLines 182 to 190: Build decoder inference model.\\n\\nLines 192 to 194: Create reverse lookup dictionaries.\\n\\nLines 197 to 227: Define decoding function for inference.\\n\\nLines 230 to 236: Test decoding on sample sequences and print results.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "# Intrepretation of the English to French translation code\n",
        "'''\n",
        "Lines 1 to 6: Model metadata ‚Äî title, author, date info, description, accelerator.\n",
        "\n",
        "Lines 8 to 29: Introduction ‚Äî explains the model purpose, dataset, and training/inference workflow.\n",
        "\n",
        "Lines 31 to 33: Section header ‚Äî Setup.\n",
        "\n",
        "Lines 35 to 39: Import libraries ‚Äî numpy, keras, os, Path.\n",
        "\n",
        "Lines 41 to 43: Section header ‚Äî Download the data.\n",
        "\n",
        "Lines 45 to 47: Download and unzip English‚ÄìFrench dataset.\n",
        "\n",
        "Lines 49 to 56: Section header ‚Äî Configuration.\n",
        "\n",
        "Lines 58 to 63: Hyperparameters and dataset path.\n",
        "\n",
        "Lines 65 to 67: Section header ‚Äî Prepare the data.\n",
        "\n",
        "Lines 69 to 73: Initialize storage lists and sets for texts and characters.\n",
        "\n",
        "Lines 74 to 76: Read dataset file.\n",
        "\n",
        "Lines 77 to 85: Process lines, add start/end tokens, store texts, collect characters.\n",
        "\n",
        "Lines 87 to 91: Sort characters, compute vocab sizes, and max sequence lengths.\n",
        "\n",
        "Lines 93 to 97: Print dataset statistics.\n",
        "\n",
        "Lines 99 to 100: Create character-to-index dictionaries.\n",
        "\n",
        "Lines 102 to 110: Initialize NumPy arrays for encoder/decoder one-hot data.\n",
        "\n",
        "Lines 112 to 121: Populate one-hot encoded arrays with sequences and padding.\n",
        "\n",
        "Lines 123 to 125: Section header ‚Äî Build the model.\n",
        "\n",
        "Lines 127 to 129: Define encoder input + LSTM + extract states.\n",
        "\n",
        "Lines 131 to 132: Store encoder states.\n",
        "\n",
        "Lines 134 to 135: Define decoder input.\n",
        "\n",
        "Lines 137 to 141: Define decoder LSTM + dense softmax output layer.\n",
        "\n",
        "Lines 143 to 145: Create training model.\n",
        "\n",
        "Lines 147 to 149: Section header ‚Äî Train the model.\n",
        "\n",
        "Lines 151 to 153: Compile model.\n",
        "\n",
        "Lines 154 to 160: Train model, save to disk.\n",
        "\n",
        "Lines 162 to 168: Section header ‚Äî Run inference (sampling).\n",
        "\n",
        "Lines 171 to 175: Reload model from disk.\n",
        "\n",
        "Lines 177 to 180: Build encoder inference model.\n",
        "\n",
        "Lines 182 to 190: Build decoder inference model.\n",
        "\n",
        "Lines 192 to 194: Create reverse lookup dictionaries.\n",
        "\n",
        "Lines 197 to 227: Define decoding function for inference.\n",
        "\n",
        "Lines 230 to 236: Test decoding on sample sequences and print results.\n",
        "'''\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  Upload pretrained model ZIP\n",
        "\n",
        "from google.colab import files\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "print(\"üìÇ Please upload your pretrained model ZIP file...\")\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "_OH3GpR5s3ic",
        "outputId": "83168f2b-8c2f-4926-f4c3-fd3d3de1518e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÇ Please upload your pretrained model ZIP file...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-8663638b-d02a-4481-bc75-fc76c9f52135\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-8663638b-d02a-4481-bc75-fc76c9f52135\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving pretrained_model.zip to pretrained_model.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the zip\n",
        "for filename in uploaded.keys():\n",
        "    zip_path = filename\n",
        "    break  # get the first uploaded file\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"/content/model\")\n",
        "print(\"‚úÖ Model files extracted to /content/model\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68A-PyQh6kP-",
        "outputId": "a9c1e3c0-936e-41d8-bed9-787139c70253"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Model files extracted to /content/model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "zip_path = \"/content/pretrained_model.zip\"\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    print(zip_ref.namelist())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wqs6o37q2P41",
        "outputId": "2a65968b-68f4-45a1-bfc1-fe96cb586d16"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['encoder-5-3000.pkl', 'decoder-5-3000.pkl']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize captions\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "import string\n",
        "\n",
        "# Download required NLTK resources\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "tokens = []\n",
        "for caption in captions:\n",
        "    # Lowercase + remove punctuation\n",
        "    caption = caption.lower().translate(str.maketrans('', '', string.punctuation))\n",
        "    # Tokenize\n",
        "    tokens.extend(word_tokenize(caption))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "titPYSOJ7T-s",
        "outputId": "8b61fc77-0474-45df-bd93-c1c0038d8321"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Build Vocabulary from captions\n",
        "from collections import Counter\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "def build_vocab(captions, threshold=5):\n",
        "    counter = Counter()\n",
        "    for caption in captions:\n",
        "        tokens = nltk.tokenize.word_tokenize(caption.lower())\n",
        "        counter.update(tokens)\n",
        "\n",
        "    # Keep only words that occur >= threshold times\n",
        "    words = [word for word, cnt in counter.items() if cnt >= threshold]\n",
        "\n",
        "    # Add special tokens\n",
        "    vocab = {}\n",
        "    vocab['<pad>'] = 0\n",
        "    vocab['<start>'] = 1\n",
        "    vocab['<end>'] = 2\n",
        "    vocab['<unk>'] = 3\n",
        "\n",
        "    for i, word in enumerate(words, 4):\n",
        "        vocab[word] = i\n",
        "\n",
        "    return vocab\n",
        "\n",
        "captions_list = [\n",
        "    \"A man riding a horse on a beach.\",\n",
        "    \"A group of people playing football.\",\n",
        "    \"A cat sitting on a mat.\"\n",
        "]\n",
        "vocab = build_vocab(captions_list, threshold=1)  # Lower threshold for demo\n",
        "\n",
        "# Encoder & Decoder initialization\n",
        "embed_size = 256\n",
        "hidden_size = 512\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "encoder = Encoder(embed_size)\n",
        "decoder = Decoder(embed_size, hidden_size, vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_oyTLiS7udA",
        "outputId": "dea5b4e6-d302-45f3-f895-bc125a53bd53"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload your custom images\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "print(\"üì∑ Please upload the images you want captions for...\")\n",
        "uploaded_images = files.upload()\n",
        "\n",
        "image_paths = []\n",
        "for filename in uploaded_images.keys():\n",
        "    path = f\"/content/{filename}\"\n",
        "    image_paths.append(path)\n",
        "\n",
        "print(f\"Uploaded {len(image_paths)} images!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "nUwG7WOE0Tm7",
        "outputId": "de30235f-e0fb-42fd-f9a6-8c25ba177ad2"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì∑ Please upload the images you want captions for...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-4419f1e4-fb28-455f-bd23-152dfcff56a1\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-4419f1e4-fb28-455f-bd23-152dfcff56a1\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving man-riding-a-horse-through-a-downhill-field.jpg to man-riding-a-horse-through-a-downhill-field.jpg\n",
            "Saving kreit-Sl0paD0U9KM-unsplash.jpg to kreit-Sl0paD0U9KM-unsplash.jpg\n",
            "‚úÖ Uploaded 2 images!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess images (example preprocessing)\n",
        "\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "def preprocess_image(img_path):\n",
        "    img = Image.open(img_path).convert('RGB')\n",
        "    img = img.resize((299, 299))\n",
        "    img_array = np.array(img) / 255.0\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    return img_array"
      ],
      "metadata": {
        "id": "nIhguddw8SrK"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to generate captions\n",
        "\n",
        "def generate_caption(image_path):\n",
        "    # Step 1: Encode image\n",
        "    processed_img = preprocess_image(image_path)\n",
        "    feature_vector = encoder.predict(processed_img)  # Extract features\n",
        "\n",
        "    # Generate description\n",
        "    # Assuming decoder model takes encoded vector & outputs sequence\n",
        "    description_tokens = decoder.predict(feature_vector)\n",
        "\n",
        "    # Convert token IDs to words (example, you must have your tokenizer)\n",
        "    # tokenizer is assumed to be loaded if available\n",
        "    if 'tokenizer.pkl' in os.listdir('/content/model'):\n",
        "        import pickle\n",
        "        with open(\"/content/model/tokenizer.pkl\", \"rb\") as f:\n",
        "            tokenizer = pickle.load(f)\n",
        "        words = [tokenizer.index_word.get(np.argmax(token), '') for token in description_tokens[0]]\n",
        "        caption = ' '.join([w for w in words if w])\n",
        "    else:\n",
        "        caption = \"Generated description (tokenizer not found)\"\n",
        "\n",
        "    return caption"
      ],
      "metadata": {
        "id": "-PL1P2T8Bqk1"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload images\n",
        "from google.colab import files\n",
        "\n",
        "print(\"\\n Please upload the images you want to caption...\\n\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Store image paths in a list\n",
        "image_paths = list(uploaded.keys())\n",
        "\n",
        "# Generate captions for uploaded images\n",
        "import os\n",
        "\n",
        "print(\"\\n Generating captions for your uploaded images...\\n\")\n",
        "\n",
        "# Loop through each uploaded image and generate a caption\n",
        "for img_path in image_paths:\n",
        "    try:\n",
        "        caption = generate_caption(img_path)\n",
        "        print(f\"{os.path.basename(img_path)} ‚Üí {caption}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Could not generate caption for {os.path.basename(img_path)}: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "id": "O2aq-WLzPFbd",
        "outputId": "654523d7-2a78-4652-c2df-5f029a3b5cc3"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Please upload the images you want to caption...\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-2c010f3e-de9c-489e-9303-8cce09169115\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-2c010f3e-de9c-489e-9303-8cce09169115\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving man-riding-a-horse-through-a-downhill-field.jpg to man-riding-a-horse-through-a-downhill-field (2).jpg\n",
            "\n",
            "üìù Generating captions for your uploaded images...\n",
            "\n",
            "Could not generate caption for man-riding-a-horse-through-a-downhill-field (2).jpg: name 'encoder' is not defined\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Running It with Keras Instead of PyTorch\n",
        "'''\n",
        "If you have a PyTorch implementation but want to run it in Keras:\n",
        "\n",
        "Steps:\n",
        "\n",
        "Model Architecture Conversion\n",
        "\n",
        "Identify the layers and structure in the PyTorch model.py.\n",
        "\n",
        "Recreate the architecture in Keras using tf.keras.layers equivalents (e.g., nn.Linear ‚Üí Dense, nn.Conv2d ‚Üí Conv2D, nn.LSTM ‚Üí LSTM).\n",
        "\n",
        "Keep parameter sizes identical so weights can be mapped.\n",
        "\n",
        "Weight Conversion\n",
        "\n",
        "PyTorch and Keras use different formats for weights.\n",
        "\n",
        "Use a library like onnx to export the PyTorch model to the ONNX format, then load into TensorFlow/Keras via onnx-tf or tf2onnx.\n",
        "\n",
        "Alternatively, manually load the .pth file, extract tensors with state_dict(), and assign them to Keras layers with layer.set_weights(), making sure dimensions match.\n",
        "\n",
        "Tokenizer & Data Preprocessing\n",
        "\n",
        "Replace PyTorch text/image preprocessing (torchvision.transforms, custom tokenizers) with Keras equivalents (tf.image, Tokenizer, TextVectorization).\n",
        "\n",
        "Training / Inference Adjustments\n",
        "\n",
        "Inference steps (model.eval() in PyTorch) translate to model.predict() in Keras.\n",
        "\n",
        "Batch handling will be via tf.data pipelines instead of PyTorch DataLoader.\n",
        "'''\n",
        "\n",
        "# Rewriting model.py in Keras (sample code)\n",
        "\n",
        "from tensorflow.keras import layers, Model, Input\n",
        "\n",
        "# Encoder\n",
        "image_input = Input(shape=(224, 224, 3))\n",
        "x = layers.Conv2D(64, (3,3), activation='relu')(image_input)\n",
        "x = layers.GlobalAveragePooling2D()(x)\n",
        "encoder_output = layers.Dense(256, activation='relu')(x)\n",
        "\n",
        "# Decoder\n",
        "caption_input = Input(shape=(None,))\n",
        "embedding = layers.Embedding(vocab_size, 256)(caption_input)\n",
        "merged = layers.Concatenate()([encoder_output, embedding])\n",
        "lstm_out = layers.LSTM(512, return_sequences=True)(merged)\n",
        "output = layers.Dense(vocab_size, activation='softmax')(lstm_out)\n",
        "\n",
        "model = Model(inputs=[image_input, caption_input], outputs=output)\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
        "\n",
        "'''\n",
        "Translating Between Japanese and English\n",
        "Steps:\n",
        "\n",
        "Use a Japanese tokenizer like MeCab or SentencePiece (because Japanese text does not have spaces).\n",
        "\n",
        "Prepare parallel corpus (e.g., JESC, Tatoeba, or Kyoto Free Translation Task dataset).\n",
        "\n",
        "Train a Seq2Seq or Transformer model (Hugging Face‚Äôs MarianMT or T5 works well).\n",
        "\n",
        "For inference, ensure proper preprocessing:\n",
        "\n",
        "Japanese ‚Üí tokenization (subwords)\n",
        "\n",
        "English ‚Üí detokenization\n",
        "\n",
        "\n",
        "\n",
        "Advanced Machine Translation Methods\n",
        "\n",
        "Attention Mechanisms (Bahdanau, Luong)\n",
        "\n",
        "Transformers (Vaswani et al., 2017) ‚Äî models like BERT, GPT, and MarianMT.\n",
        "\n",
        "Multilingual Models ‚Äî single model trained on multiple languages (mBART, mT5).\n",
        "\n",
        "Pre-trained Models with Fine-tuning ‚Äî start with a general MT model, fine-tune on your specific domain.\n",
        "\n",
        "\n",
        "\n",
        "Generating Images from Text (Opposite of Captioning)\n",
        "Techniques:\n",
        "\n",
        "Diffusion Models (e.g., Stable Diffusion, DALL¬∑E 2, MidJourney)\n",
        "\n",
        "GANs (StackGAN, AttnGAN ‚Äî text-conditioned image generation)\n",
        "\n",
        "CLIP + Diffusion (guiding generation with text embeddings)\n",
        "\n",
        "Neural Rendering (NeRF-based, though mainly 3D)\n",
        "\n",
        "Basic Flow for Text-to-Image:\n",
        "\n",
        "Encode text into vector representation (BERT/CLIP encoder).\n",
        "\n",
        "Feed into generative model (Diffusion or GAN).\n",
        "\n",
        "Generate image pixels conditioned on the text embedding.\n",
        "'''"
      ],
      "metadata": {
        "id": "fNkb11_WPYkO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}